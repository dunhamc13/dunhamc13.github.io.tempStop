---
layout: post
title:  "SpaceTime"
---

# Poisoning Defenses in Federated Learning 
**Thanks for stopping by!**

Recently I have been working on my Thesis.  I am studying methods to secure the IoT environment. IoT presents many challenges due to the heterogeneous and ubiqitous nature of the IoT sensors.

Specifically, I have created a Recurrent Neural Network for anomaly-detection in a federated machine learning (FL) intrusion detection system (IDS). However, FL environments are susceptible to poisoning attacks.

Poisoning attacks are when an attacker modifies the gradients or the weights used by the FL model to aggregate the local client data in order to effect the convergence of the model.

I believe that these poisoning attacks can be defined by a 3 + 1 dimension problem of space and time. The spatial distances between the attackers as well as the time can be used to identify them.

This has led to me using state of the art Deep Learning Models to prove that spacetime can be used to solve the attacker identification problem in poisoning attacks.
